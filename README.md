# ğŸ“Š Projeto Final - Pipeline de Dados e Machine Learning

## ğŸ¯ VisÃ£o Geral

Este projeto implementa um pipeline completo de dados e machine learning para anÃ¡lise de recompra de clientes, utilizando Apache Airflow para orquestraÃ§Ã£o, Hadoop HDFS para armazenamento distribuÃ­do, e Streamlit para visualizaÃ§Ã£o dos resultados.

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚    â”‚   Apache        â”‚    â”‚   SQL Server    â”‚
â”‚   (Origem)      â”‚â”€â”€â”€â–¶â”‚   Airflow       â”‚â”€â”€â”€â–¶â”‚   (Destino)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Hadoop HDFS   â”‚
                       â”‚   (Storage)     â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Streamlit     â”‚
                       â”‚   (Dashboard)   â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Funcionalidades

### ETL Pipeline
- **ExtraÃ§Ã£o**: Dados do PostgreSQL (sistema transacional)
- **TransformaÃ§Ã£o**: Limpeza e modelagem dimensional
- **Carga**: Data Warehouse no SQL Server

### Machine Learning
- **Problema**: PrevisÃ£o de recompra em 90 dias
- **Modelos**: Logistic Regression, Random Forest, Gradient Boosting
- **AvaliaÃ§Ã£o**: ROC AUC, Accuracy, Precision, Recall, F1-Score

### VisualizaÃ§Ã£o
- Dashboard interativo com Streamlit
- ComparaÃ§Ã£o de modelos
- Simulador de previsÃµes

## ğŸ“ Estrutura do Projeto

```
projeto_final/
â”œâ”€â”€ dags/                           # DAGs do Airflow
â”‚   â”œâ”€â”€ check_db_conexao.py        # VerificaÃ§Ã£o de conexÃµes
â”‚   â”œâ”€â”€ dag_gerar_slice_analitico.py # GeraÃ§Ã£o do slice analÃ­tico
â”‚   â”œâ”€â”€ dag_treinamento_modelos.py  # Treinamento de ML
â”‚   â”œâ”€â”€ dim*.py                     # ETL das dimensÃµes
â”‚   â””â”€â”€ fato*.py                    # ETL das tabelas fato
â”œâ”€â”€ data/                           # Dados processados
â”‚   â”œâ”€â”€ analytical_slice/           # Dados para ML (particionado)
â”‚   â”œâ”€â”€ feature_store/              # Features preparadas
â”‚   â””â”€â”€ models/                     # Modelos treinados
â”œâ”€â”€ logs/                           # Logs do Airflow
â”œâ”€â”€ init-db.sh/                     # Scripts de inicializaÃ§Ã£o
â”œâ”€â”€ docker-compose.yaml             # OrquestraÃ§Ã£o dos containers
â”œâ”€â”€ dashboard.py                    # Dashboard Streamlit
â””â”€â”€ requirements.txt                # DependÃªncias Python
```

## ğŸ› ï¸ Tecnologias Utilizadas

- **OrquestraÃ§Ã£o**: Apache Airflow
- **Bancos de Dados**: PostgreSQL, SQL Server
- **Big Data**: Hadoop HDFS
- **Machine Learning**: Scikit-learn
- **VisualizaÃ§Ã£o**: Streamlit
- **ContainerizaÃ§Ã£o**: Docker & Docker Compose
- **Linguagem**: Python

## ğŸ“‹ PrÃ©-requisitos

- Docker e Docker Compose
- 8GB+ de RAM disponÃ­vel
- Portas livres: 8080 (Airflow), 8501 (Streamlit), 5432 (PostgreSQL), 1450 (SQL Server)

## ğŸš€ Como Executar

### 1. ConfiguraÃ§Ã£o Inicial

```bash
# Clone o repositÃ³rio
git clone <repository-url>
cd projeto_final

# Configure as variÃ¡veis de ambiente
cp .env.example .env
# Edite o arquivo .env com suas configuraÃ§Ãµes
```

### 2. Subir os ServiÃ§os

```bash
# Iniciar todos os containers
docker-compose up -d

# Verificar status dos serviÃ§os
docker-compose ps
```

### 3. Acessar as Interfaces

- **Airflow**: http://localhost:8080
- **Streamlit Dashboard**: http://localhost:8501
- **Hadoop NameNode**: http://localhost:9870

### 4. Executar o Pipeline

1. Acesse o Airflow (usuÃ¡rio/senha definidos no .env)
2. Execute as DAGs na seguinte ordem:
   - `01_check_db_connections`
   - `etl_dim*` (dimensÃµes)
   - `etl_fato*` (tabelas fato)
   - `dag_gerar_slice_analitico_para_ml`
   - `dag_treinamento_modelo_recompra_90d`

## ğŸ“Š DAGs DisponÃ­veis

### VerificaÃ§Ã£o e ETL
- **check_db_conexao**: Testa conectividade com bancos
- **etl_dimcliente**: ETL da dimensÃ£o cliente
- **etl_dimproduto**: ETL da dimensÃ£o produto
- **etl_dimvendedor**: ETL da dimensÃ£o vendedor
- **etl_dimfornecedor**: ETL da dimensÃ£o fornecedor
- **etl_dimformapagamento**: ETL da dimensÃ£o forma pagamento
- **etl_dimsituacaotitulo**: ETL da dimensÃ£o situaÃ§Ã£o tÃ­tulo

### Tabelas Fato
- **etl_fatovenda**: ETL das vendas
- **etl_fatocontasreceber**: ETL contas a receber
- **etl_fatocontaspagar**: ETL contas a pagar

### Machine Learning
- **dag_gerar_slice_analitico**: Prepara dados para ML
- **dag_treinamento_modelo_recompra_90d**: Treina modelos preditivos

## ğŸ¤– Modelos de Machine Learning

### Problema de NegÃ³cio
Prever se um cliente farÃ¡ uma nova compra nos prÃ³ximos 90 dias apÃ³s uma transaÃ§Ã£o.

### Features Utilizadas
- Valor total da venda
- Quantidade de itens
- Valor da parcela
- NÃºmero da parcela
- Tipo do cliente (fÃ­sica/jurÃ­dica)
- SituaÃ§Ã£o do tÃ­tulo
- Forma de pagamento

### Modelos Testados
1. **Logistic Regression**: Modelo linear interpretÃ¡vel
2. **Random Forest**: Ensemble de Ã¡rvores de decisÃ£o
3. **Gradient Boosting**: Boosting sequencial

### MÃ©tricas de AvaliaÃ§Ã£o
- **ROC AUC**: MÃ©trica principal para seleÃ§Ã£o
- **Accuracy**: PrecisÃ£o geral
- **Precision**: Evita falsos positivos
- **Recall**: Captura verdadeiros positivos
- **F1-Score**: Balanceamento precision/recall

## ğŸ“ˆ Dashboard

O dashboard Streamlit oferece:

1. **ComparaÃ§Ã£o de Modelos**: VisualizaÃ§Ã£o das mÃ©tricas
2. **AnÃ¡lise do Melhor Modelo**: Detalhes e importÃ¢ncia das features
3. **Simulador**: Interface para fazer previsÃµes em tempo real

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### VariÃ¡veis de Ambiente (.env)
```env
# Airflow
AIRFLOW_ADMIN_USER=admin
AIRFLOW_ADMIN_PASSWORD=admin
AIRFLOW_ADMIN_EMAIL=admin@example.com

# PostgreSQL (Source)
POSTGRES_HOST=host.docker.internal
POSTGRES_USER=postgres
POSTGRES_PASSWORD=password
POSTGRES_DB=database

# SQL Server (Target)
MSSQL_PASSWORD=YourStrong@Passw0rd
```

### Volumes Docker
- `postgres-db-volume`: Dados do PostgreSQL
- `sqlserver-data`: Dados do SQL Server
- `hadoop-namenode`: Metadados HDFS
- `hadoop-datanode`: Dados HDFS

## ğŸ› Troubleshooting

### Problemas Comuns

1. **Containers nÃ£o sobem**:
   ```bash
   docker-compose down -v
   docker-compose up -d
   ```

2. **Erro de conexÃ£o com banco**:
   - Verifique as variÃ¡veis no .env
   - Execute a DAG `check_db_conexao`

3. **Falta de memÃ³ria**:
   - Aumente recursos do Docker
   - Monitore com `docker stats`

4. **Portas ocupadas**:
   - Altere as portas no docker-compose.yaml
   - Verifique com `netstat -tulpn`

## ğŸ“ Logs e Monitoramento

- **Airflow Logs**: `logs/dag_id/run_id/task_id/`
- **Container Logs**: `docker-compose logs <service>`
- **Hadoop Logs**: Interface web do NameNode

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature
3. Commit suas mudanÃ§as
4. Push para a branch
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo LICENSE para detalhes.

## ğŸ‘¥ Autores

- **Israel** -
- **Christian**-
- **JoaoPedro**-

## ğŸ™ Agradecimentos

- Digital College - Curso Python para Dados
- Comunidade Apache Airflow
- DocumentaÃ§Ã£o Scikit-learn
